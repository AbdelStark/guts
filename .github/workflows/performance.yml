name: Performance Benchmarks

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 0 * * *'  # Daily at midnight UTC
  workflow_dispatch:
    inputs:
      run_full_suite:
        description: 'Run full benchmark suite'
        required: false
        default: 'false'
        type: boolean

env:
  CARGO_TERM_COLOR: always
  RUSTFLAGS: "-C debuginfo=2"

jobs:
  criterion-benchmarks:
    name: Criterion Benchmarks
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          components: llvm-tools-preview

      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-bench-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-bench-
            ${{ runner.os }}-cargo-

      - name: Install RocksDB dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y librocksdb-dev libclang-dev

      - name: Run Criterion benchmarks
        run: |
          cargo bench -p guts-storage --bench storage_bench -- --noplot
          cargo bench -p guts-storage --bench concurrent_bench -- --noplot

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: criterion-results
          path: target/criterion/
          retention-days: 30

      - name: Download previous benchmark results
        uses: actions/cache@v4
        with:
          path: benchmark-baseline
          key: benchmark-baseline-${{ github.ref_name }}
          restore-keys: |
            benchmark-baseline-main

      - name: Compare with baseline
        run: |
          if [ -d "benchmark-baseline" ]; then
            echo "Comparing with baseline..."
            # Copy baseline for comparison
            cp -r benchmark-baseline target/criterion-baseline 2>/dev/null || true
          fi

      - name: Save as new baseline
        if: github.ref == 'refs/heads/main'
        run: |
          mkdir -p benchmark-baseline
          cp -r target/criterion/* benchmark-baseline/ 2>/dev/null || true

  memory-profiling:
    name: Memory Profiling
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y valgrind heaptrack

      - name: Build with debug info
        # Exclude guts-desktop (requires GTK/webkit2gtk on Linux)
        run: cargo build --release --workspace --exclude guts-desktop

      - name: Run memory profile
        run: |
          # Start node in background
          timeout 30 ./target/release/guts-node --api-addr 127.0.0.1:8080 &
          NODE_PID=$!
          sleep 5

          # Generate some load
          for i in $(seq 1 100); do
            curl -s http://localhost:8080/health > /dev/null || true
          done

          # Get memory stats
          ps -o pid,rss,vsz -p $NODE_PID || true
          kill $NODE_PID 2>/dev/null || true

  k6-load-tests:
    name: K6 Load Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45
    if: github.event_name == 'schedule' || github.event.inputs.run_full_suite == 'true'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Install K6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install -y k6

      - name: Build release binary
        run: cargo build --release --bin guts-node

      - name: Start Guts node
        run: |
          ./target/release/guts-node --api-addr 127.0.0.1:8080 &
          sleep 5
          curl -f http://localhost:8080/health

      - name: Run API read tests
        run: |
          k6 run --env GUTS_URL=http://localhost:8080 \
            --duration 2m --vus 20 \
            infra/benchmarks/k6/api_reads.js

      - name: Run Git push tests
        run: |
          k6 run --env GUTS_URL=http://localhost:8080 \
            --duration 2m --vus 10 \
            infra/benchmarks/k6/git_push.js

      - name: Run concurrent connection tests
        run: |
          k6 run --env GUTS_URL=http://localhost:8080 \
            --duration 2m --vus 50 \
            infra/benchmarks/k6/concurrent.js

      - name: Upload K6 results
        uses: actions/upload-artifact@v4
        with:
          name: k6-results
          path: |
            *.json
            *.html
          retention-days: 30

  performance-report:
    name: Generate Performance Report
    runs-on: ubuntu-latest
    needs: [criterion-benchmarks]
    if: always()

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download Criterion results
        uses: actions/download-artifact@v4
        with:
          name: criterion-results
          path: criterion-results

      - name: Generate summary
        run: |
          echo "## Performance Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Criterion Benchmarks" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # List benchmark groups
          if [ -d "criterion-results" ]; then
            for dir in criterion-results/*/; do
              if [ -d "$dir" ]; then
                name=$(basename "$dir")
                echo "- **$name**" >> $GITHUB_STEP_SUMMARY
              fi
            done
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "See artifacts for detailed reports." >> $GITHUB_STEP_SUMMARY

      - name: Check for regressions
        run: |
          # Simple regression check script
          echo "Checking for performance regressions..."

          # This would parse criterion output and fail if significant regression
          # For now, just print info
          echo "Performance check completed"

  notify-on-regression:
    name: Notify on Regression
    runs-on: ubuntu-latest
    needs: [performance-report]
    if: failure() && github.ref == 'refs/heads/main'

    steps:
      - name: Create issue for regression
        uses: actions/github-script@v7
        with:
          script: |
            const title = 'Performance Regression Detected';
            const body = `
            A performance regression was detected in the benchmarks.

            **Run:** ${context.runId}
            **Commit:** ${context.sha}

            Please investigate the benchmark results.
            `;

            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['performance', 'regression']
            });
